A Behavioural Model for Consumer Reputation
Anirban Basu, Ian Wakeman and Dan Chalmers Department of Informatics, University of Sussex
{A.Basu, ianw and D.Chalmers}@sussex.ac.uk

Introduction
FUTURE interactions between a client (service consumer) and a server (service provider) in a networked environment are often unaffected by past observations or any form of local or global behavioural history. Instead, ﬁltering of network connections or variations of service levels are dependent on other techniques such as content ﬁltering in case of messaging systems (e.g., email). In an effort to inform policy decisions for future interactions, some work has been done towards developing an architecture for large-scale sharing of behavioural history [ABP05]. Others [GKF+06, GH04] have proposed use of reputation mechanisms to combat the problem of email spam.

Research question: We explore the research question: can a local and a global reputation scheme based on behavioural history of long-lived network identities be used to implement policies for future network interactions?

Assuming that a long-lived identity infrastructure is in place, we propose a reputation scheme based on behavioural history of such identities. In many scenarios, network identities are either short-lived or anonymous. A proposal for developing long-lived identities using group memberships is discussed in [WCF07]. When identity of the client is anonymous or short-lived, a fall-back option, such as best effort service, will be used.
Acceptable behaviour model
THERE needs to be means for deﬁning “acceptable behaviour” for network actors. Service contracts, which include Acceptable Use Policies and Service Level Agreements, provide good starting points but these are usually legal agreements with vague technical terms. We are exploring the possibilities of identifying technical terms. We are developing an acceptable behaviour model, which is a mapping of technical terms to notions of good or bad behaviour through a logic-based formalism, such as Event Calculus [KS86]. This formalism will help quantising good or bad behaviour in accordance with service contracts.
Local reputation
WE have deﬁned a local reputation response to change in quantised behaviour. We have experimented with some mathematical models to best represent the expected reputation response. We will use the terms score and rank to denote reputation of a consumer and of a provider respectively. Let us denote score variable with r; consumer behaviour variable with b; positive score saturation with rpsat; negative saturation with rnsat; and two adjustable response parameters λ and µ. Also, for any event (v) for which a change of behaviour is noted, the corresponding cumulative behaviour is bv and the corresponding reputation is rv. Further p and n sufﬁxes will signify positive and negative respectively.

The equation for good reputation getting better with good behaviour is:

r = rpsat 1 − e−λb for ∆b > 0, b > 0, rv−1 ≥ 0

(1)

and the equation for bad reputation getting worse with bad behaviour is:

r = rnsat 1 − eλb for ∆b < 0, b < 0, rv−1 ≤ 0

(2)

and the equation for good reputation (rvp) getting worse with bad behaviour is:

r = rvpb bvp

for

∆b < 0, b > 0, rv−1 > rv ≥ 0

(3)

and rvp = rpsat 1 − e−λbvp

and the equation for bad reputation (rvn) getting better with good behaviour is:

r=

rvn 1 − eµbvn

1 − eµb

for ∆b > 0, b < 0, rv−1 < rv ≤ 0

(4)

and rvn = rnsat 1 − eλbvn

Time decay: Saturated reputation indicates either “too good” or “too bad” values. Therefore, a de-

cay with no activity over time helps a saturated bad reputation to recover; and it also questions a

saturated good reputation. A neutral zone [rndef rpdef ] (positive and negative default) is deﬁned for this purpose. Positive reputation higher than rpdef decays to positive default, while negative reputation value lower than rndef increases to negative default. An adjustable decay rate parameter is introduced in this context. The equation for positive reputation decaying over time is given as:

r=

rvp 1 − t2 rpdef

for r ≥ rpdef for r < rpdef

(5)

and the equation for negative reputation increasing over time is given as:

r=

rvn 1 − t2 rndef

for r ≤ rndef for r > rndef

(6)

Reputation score (r) Reputation score (r)

1.5

1.25 1

Theoretical positive saturation (r )
psat

0.75

Arbitrary positive reputation (r )
v
p

0.5

0.25

0

−0.25 −0.5

Arbitrary negative reputation (r )
v
n

−0.75

−1 −1.25

Theoretical negative saturation (r )
nsat

−1.5

−1000 −800

−600

−400

−200

0

200

400

600

800

1000

Behaviour (b)

1.5

1.25 1

Theoretical positive saturation (r )
psat

0.75 0.5

Arbitrary positive saturation (r )
v
p

0.25 0
−0.25 −0.5

Positive default (r )
pdef
Negative default (r )
ndef
Arbitrary negative saturation (r )
v
n

−0.75

−1 −1.25

Theoretical negative saturation (r )
nsat

−1.5 0

100

200

300

400

500

600

700

800

900

1000

Time (t)

(a)

(b)

Figure 1: Part (a): local reputation response to behaviour; part (b): the time decay of local reputation.

Global reputation

THE local scores are aggregated to develop a global score. The global score can be stored in an infrastructure with single administrative control. The global score is calculated, at query time, over a window of previously submitted local scores. If local reputation score from provider i is denoted by rlocali; rank of the provider is ranki; reputation to behaviour response parameters are λi and µi; time at which the reputation score is reported is treporti; and time at which global score is calculated is t. Calculated over a window of n submitted local scores, the ith component of the global score is given as:

rglobali =

rlocaliranki rlocaliranki

1 − λi i(t − treporti)2 1 − µi i(t − treporti)2

for 0 ≤ rlocali ≤ 1 for − 1 ≤ rlocali ≤ 0

(7)

and thus, the global score is given as:

rglobal =

n i=1

rglobali

n

(8)

If the requesting provider j has already submitted its own component of global score in the past then the jth component is ignored; hence:

rglobal =

n i=1

rglobali

where

i=j

n−1

(9)

We are investigating use of other statistical measures, such as standard deviation or distributions, along with the weighted average to detect inconsistencies in the global components of the score. This, in turn, forms a defense mechanism for certain attacks on the model.

Global score aggregation: The global score is reported to a score aggregation system (SAS) is described by a six step process as follows.
1. At the start of service provision, provider (P) requests authorisation from consumer (C) to look up C’s global score (rglobalC) stored in the SAS
2. C sends authorisation token (AT) to P, which also contains the permit to report a score for C. In addition, C notiﬁes SAS that AT has been created.
3. P provides service to C and makes local observations. If a service is continuous, P can submit scores several times but for each submission a new AT is required.
4. At any time, P can send the local score to SAS for aggregation.
5. SAS contacts C (or its agent) with an optional requirement to submit its assessment for P (rank of P). If C declines to comment or is unavailable, SAS will assume a value 1 (highest) for P’s rank.
6. SAS updates the rank for P only if C’s global score at that point (prior to the current aggregation) is positive. SAS aggregates C’s score and invalidates AT.
Provider ranking is intuitive at the moment, such as “did I like (range: (0 1]) the service I was provided?”. We are investigating if this can be formalised. Storage and calculation of provider ranks can also be done over a resizable window of submitted ranks.
Implementation and simulation (future work)
MATHEMATICAL validation of the model is being achieved through the use of differential calculus. This will be followed by the implementation. The simulation of the model will be done based on any available real world input data (e.g., The Internet Trafﬁc Archive1) as well as synthetic data that represent the full spectrum of users with behaviour between fully malicious and fully non-malicious. The results will illustrate how well the proposed model can act as a security measure augmented with existing policies to protect unsolicited transactions over a network. We expect that consumers having accidental and occasional short spells of bad behaviour but generally good behaviour otherwise should not have their reputation badly affected. However, consumers consistently behaving bad will have their service levels drop to minimum or be cut off.

We are also interested in an experiment to use such consumers scores as an incentive mechanism in a peer-to-peer content distribution system. In addition to this, we will simulate a variety of attacks and check our model for defense against such attacks.

References
[ABP05] M. Allman, E. Blanton, and V. Paxson. An Architecture for Developing Behavioral History. Proc. Workshop on Steps to Reducing Unwanted Trafﬁc on the Internet, 2005.
[GH04] J. Golbeck and J. Hendler. Reputation Network Analysis for Email Filtering. Proceedings of Conference on Email and Anti-Spam (CEAS), 2004.
[GKF+06] S. Garriss, M. Kaminsky, M.J. Freedman, B. Karp, D. Mazie` res, and H. Yu. Re: Reliable Email. Proceedings of the 3rd Symposium of Networked Systems Design and Implementation (NSDI ’06), 2006.
[KS86] R.A. Kowalski and M.J. Sergot. A Logic-based Calculus of Events. New Generation Computing, 4(1):67–95, 1986.
[WCF07] Ian Wakeman, Dan Chalmers, and Michael Fry. Reconciling privacy and security in pervasive computing: The case for pseudonymous group membership. Submitted for publication, June 2007.

1http://ita.ee.lbl.gov/

IWSOS 2007, International Workshop on Self-Organizing Systems, 11-13 September 2007, The Lake District, UK

